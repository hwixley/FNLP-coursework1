lm_stats=
best10_ents=
worst10_ents=
answer_open_question_3=
answer_open_question_4=
mean=
std=
best10_ascci_ents=
worst10_ascci_ents=
best10_non_eng_ents=
worst10_non_eng_ents=
answer_open_question_6=
naive_bayes_vocab_size=13521
naive_bayes_prior={'V': 0.47766934282005674, 'N': 0.5223306571799433}
naive_bayes_likelihood=[0.0001330380393641162, 1.3515294883759858e-05, 0.00013365897031402744, 1.2250662767947985e-05, 0.00013643620128912556, 7.163413706196727e-05, 7.625530748937835e-05]
naive_bayes_posterior=[{'V': 0.5775851887970787, 'N': 0.42241481120292135}, {'V': 0.22034804456594828, 'N': 0.7796519554340516}, {'V': 0.762975005655084, 'N': 0.23702499434491603}, {'V': 0.762975005655084, 'N': 0.23702499434491603}, {'V': 0.9852820182130485, 'N': 0.014717981786951596}]
naive_bayes_classify=['V', 'N']
naive_bayes_acc=0.7843525625154741
answer_open_question_8='The best accuracy was achieved using a sequence of words. Indicating that\nthis model is most useful when passed a sequence of words.\n\nMy NB accuracy is worse than all LR scores in Table 1. I believe this\ndifference can mainly be attributed to the NB independence assumption\nas this infers probability distributions about features that are likely\nnot true. Thus a model that does not assume any distribution would be\nmore useful.'
lr_predictions=
answer_open_question_9=
