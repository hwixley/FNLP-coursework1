lm_stats=[5579336, 0.3116466822608252, 0.9853501906482038, 1.4536908944718608e-06, 0.005158178014182952, 0.348077988641086]
best10_ents=[(5.137306855634625, ['s', 's', 's', 's', 's', 's', 's', 's', 's', 's']), (5.816790848534221, ['s', 'o', 's', 'o', 's']), (5.894416382928467, ['d', 'd', 'd', 'd', 'd']), (5.894416382928468, ['d', 'd', 'd', 'd', 'd', 'd']), (6.167249087409163, ['d', 'd', 'd', 'd', 'd', 'd', 'd', 'd', 'd', 'p']), (6.836016837883614, ['o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o']), (6.9792075989299756, ['l', 'a', 't', 'e', 'r', 'a', 'l']), (7.025628663599985, ['l', 'e', 'o', 'n', 'a', 'r', 'd', 'o']), (7.1337094045941924, ['a', 'c', 'f', 'f', 'i', 'r', 't']), (7.413609689710126, ['a', 'a', 'a', 'a', 'a', 'b', 'g', 'g', 'h', 'h', 'i', 'i', 'k', 'm', 'n', 'n', 'o', 's', 's', 't', 't', 't', 't', 'w', 'z'])]
worst10_ents=[(396.75784720951356, ['ipadの情報を一通り吸収する', '現時点ではいろいろと不透明な部分が多いので実際に手に取って動かしてみないともなんとも言えないなあ', 'でもこのようなジャンルのマシンはありだと個人的には思います', 'iphoneに関する事は何にもなかったのですね', '残念']), (399.56395680013185, ['金融規制法案的には肩透かしだったオバマ大統領の一般教書演説のおかげでドル円は日中グダグダでしたが', '演説の中身自体は景気対策の具体案が示されたこともあり', '全般的に好感され', 'リスク回避の巻き戻しからクロス円が少し戻しました', 'kakakufx']), (407.18513333900614, ['と言いつつもやっぱり笑えない時はあるよなあ', '笑っても自分の笑顔が汚らわしく思えてすぐ止めちゃうの', '自分が息してるだけで悲しくてぼろぼろ泣いてる時期もあった', '今の自分に必要な経験だったとは思うけど', '出来ればあんな感情は二度とごめんだ']), (409.5393708703471, ['人生初面接官終了', 'やはり面接してみないと分からない事が多いなと思うことしきり', '書類選考で絞り込まず', '可能な範囲で人数を増やして良かった', '面接中に机に肘をついて手をごにつけたりとかありえねー態度を取る人もいたので', 'やはりゼーレの査問みたいに全裸にして立たせた方がいいかもしれません']), (417.7792022300406, ['知識欲というのは不随意筋でできている', 'どうせ人間には永久に解明できないんだから', '宇宙はある時点で生まれたのか', 'それとも永遠の過去から存在しているのかなんてことを追究するなと言ってもムダだ', '心臓に止まれと命令しても止まらないのと同じことだ']), (438.3983902773587, ['一部tlでは', 'ソロス氏のギリシャ債に関するコメントが話題になっています', '昨日のセミナーで申し上げたようにギリシャがユーロから離脱シナリオはありえず', 'ユーロにとどまるべく財政規律を引き締めると考えるべきです', 'を超えていますし検討に値すべきかもしれません']), (453.09276520015544, ['中身の羽毛は精製過程で殺菌処理しているから', '羽毛布団からダニが湧くことはない', 'あと羽毛布団の生地は糸の打ち込み本数が多く', '羽毛の吹き出しを防ぐ目つぶし加工をしているからダニは羽毛ふとんの生地を通過できない', 'ただダニが布団に付着することはあるから手入れは必要']), (470.7495466852126, ['あおたにゆなりなやらゆらやみよなたやなゆにやわやまわやなゆ', 'ょらをまなゆにらやにやまなはらなよりなやらさかさちねらからさ', 'か', 'な', 'かあわかやならなたはやぬらゆなりゆらにゆらまらまはまらまなまゎなまはまらめまさまかやかまはたらたさまさたへたはまかまはまらまさまかまらた']), (474.28090298222435, ['作品によっては怪人でありながらヒーロー', 'あるいはその逆', 'というシチュエーションも多々ありますが', 'そうした事がやれるのもやはり怪人とヒーローと言うカテゴリが完成しているからだと思うんですよね', 'あれだけのバリエーションがありながららしさを失わないデザインにはまさに感服です']), (484.8749718732588, ['ネット大衆の取り込みは急務である', 'しかし', '大手マスメディアがネット大衆を迎合すれば一般大衆からそっぽを向かれる恐れがある', '一般大衆とネット大衆の双方を取り込む方法はどのようなものが考えられるか', 'その解決策の一つとして挙げたいのがあらたな発信基地をネット上に構築することである'])]
answer_open_question_3='The entropy values represent the average uncertainty the model\nhas with classifying all the words in the given tweet.\nThe first tweets are all English words, the most common being\nconjunctions ("and"), noun articles ("the"), and nouns\n("weather", "love").\nThe last tweets mainly consisted of non-ASCII logograms from\nother languages. This was to be expected given these languages\nare evidently not likely to be used in an English tweet.'
answer_open_question_4='We should remove all non-English tweets (non-ASCII) from the corpus\nas these characters/words are obviously not relevant for\ndeveloping an English NL model.\nWe can identify non-English tweets by checking if they contain \nnon-ASCII characters as ASCII is only used for the English language.'
mean=19.891597437411352
std=3.793906301928083
best10_ascci_ents=[(5.137306855634625, ['s', 's', 's', 's', 's', 's', 's', 's', 's', 's']), (5.816790848534221, ['s', 'o', 's', 'o', 's']), (5.894416382928467, ['d', 'd', 'd', 'd', 'd']), (5.894416382928468, ['d', 'd', 'd', 'd', 'd', 'd']), (6.167249087409163, ['d', 'd', 'd', 'd', 'd', 'd', 'd', 'd', 'd', 'p']), (6.836016837883614, ['o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o']), (6.9792075989299756, ['l', 'a', 't', 'e', 'r', 'a', 'l']), (7.025628663599985, ['l', 'e', 'o', 'n', 'a', 'r', 'd', 'o']), (7.1337094045941924, ['a', 'c', 'f', 'f', 'i', 'r', 't']), (7.413609689710126, ['a', 'a', 'a', 'a', 'a', 'b', 'g', 'g', 'h', 'h', 'i', 'i', 'k', 'm', 'n', 'n', 'o', 's', 's', 't', 't', 't', 't', 'w', 'z'])]
worst10_ascci_ents=[(29.76197785515775, ['dpp', 'empat', 'pilihan', 'proton', 'sekolah', 'uum']), (29.762470574526013, ['beijosmeliguem', 'galere', 'lt', 'saindoo', 'to']), (29.762541946258132, ['aja', 'ampun', 'haha', 'kale', 'nebeng', 'seharusnya', 'tadi', 'ya', 'yuuuu']), (29.764310270828762, ['agama', 'blajar', 'gaq', 'huhh', 'ketinggalan', 'kotak', 'lg', 'pensil']), (29.76582748952513, ['drama', 'emak', 'inheritance', 'korea', 'lagiii', 'liatin', 'nonton', 'shining']), (29.76630542396939, ['ahsuahsaushaushau', 'desde', 'ele', 'filme', 'gameei', 'lautner', 'lavagirl', 'no', 'no', 'que', 'rt', 'sharkboy', 'taylor', 'vi']), (29.766820366848318, ['aja', 'begitu', 'biasa', 'biasa', 'diomongin', 'geli', 'jg', 'kok', 'nggak', 'sih', 'uda', 'wakakakakakakaka', 'ya']), (29.769108513376153, ['ahora', 'entendez', 'hahaahha', 'jua', 'me', 'xd']), (29.769550506081487, ['booth', 'eifersüchtig', 'is', 'lol', 'ohoh']), (29.77076294850442, ['a', 'ações', 'anunciou', 'desabam', 'deverá', 'e', 'feira', 'motorola', 'motorola', 'nesta', 'para', 'prejuízo', 'prevê', 'que', 'quinta', 'registra', 'trimestre'])]
best10_non_eng_ents=[(23.68587137105652, ['com', 'escuta', 'eu', 'letras', 'musicas', 'ou', 'perigosa', 'rt', 'só', 'sou', 'sugestivas', 'toda']), (23.686214913156874, ['cd', 'colocou', 'da', 'dela', 'escutarem', 'fã', 'já', 'maximo', 'no', 'o', 'pros', 'rt', 'todo', 'via', 'vizinhos', 'volume']), (23.686464645754057, ['blog', 'cuando', 'este', 'puedas', 'revisa']), (23.687150865945952, ['calledd', 'doeeee', 'dudeee', 'finnaaa', 'hitt', 'in', 'lovee', 'misss', 'duggansss', 'school', 'so', 'thee', 'thingg', 'thiss', 'thisss', 'up']), (23.687338602510174, ['beverly', 'em', 'hills', 'passeando', 'perry']), (23.687527593608195, ['cômico', 'engraçado', 'o', 'o', 'fosse', 'não', 'nossa', 'seria', 'se']), (23.687555695555616, ['aqui', 'desabafar', 'é', 'eu', 'horas', 'mas', 'odeio', 'preciso', 'que', 'tem']), (23.68790789886512, ['announced', 'date', 'god', 'iii', 'of', 'officially', 'release', 'war']), (23.68800782652514, ['cgc', 'in', 'only', 'parker', 'peter', 'special', 'todays']), (23.68820027795355, ['a', 'acaba', 'al', 'al', 'canal', 'chávez', 'de', 'dejó', 'del', 'diálogo', 'estudiantes', 'le', 'los', 'pasar', 'pavor', 'pimentel', 'presi', 'que', 'raspar', 'recuerden', 'rt', 'tiene'])]
worst10_non_eng_ents=[(29.76197785515775, ['dpp', 'empat', 'pilihan', 'proton', 'sekolah', 'uum']), (29.762470574526013, ['beijosmeliguem', 'galere', 'lt', 'saindoo', 'to']), (29.762541946258132, ['aja', 'ampun', 'haha', 'kale', 'nebeng', 'seharusnya', 'tadi', 'ya', 'yuuuu']), (29.764310270828762, ['agama', 'blajar', 'gaq', 'huhh', 'ketinggalan', 'kotak', 'lg', 'pensil']), (29.76582748952513, ['drama', 'emak', 'inheritance', 'korea', 'lagiii', 'liatin', 'nonton', 'shining']), (29.76630542396939, ['ahsuahsaushaushau', 'desde', 'ele', 'filme', 'gameei', 'lautner', 'lavagirl', 'no', 'no', 'que', 'rt', 'sharkboy', 'taylor', 'vi']), (29.766820366848318, ['aja', 'begitu', 'biasa', 'biasa', 'diomongin', 'geli', 'jg', 'kok', 'nggak', 'sih', 'uda', 'wakakakakakakaka', 'ya']), (29.769108513376153, ['ahora', 'entendez', 'hahaahha', 'jua', 'me', 'xd']), (29.769550506081487, ['booth', 'eifersüchtig', 'is', 'lol', 'ohoh']), (29.77076294850442, ['a', 'ações', 'anunciou', 'desabam', 'deverá', 'e', 'feira', 'motorola', 'motorola', 'nesta', 'para', 'prejuízo', 'prevê', 'que', 'quinta', 'registra', 'trimestre'])]
answer_open_question_6='Problems:\n1. The magnitude of words in English can result in the sparse\ndata problem as some words only occur rarely or not at all. Thus\nresulting in a large resulting a large entropy \n2. Which words can be classified as "proper English"\n3. '
naive_bayes_vocab_size=13521
naive_bayes_prior={'N': 0.5223306571799433, 'V': 0.47766934282005674}
naive_bayes_likelihood=[7.645645775585578e-05, 7.437719469104356e-05, 0.00012304032772425798, 7.39304665711192e-05, 7.394179345097604e-05, 7.572782710921218e-05, 7.589415018154868e-05]
naive_bayes_posterior=[{'N': 0.5218155149898457, 'V': 0.4781844850101543}, {'N': 0.522495792562622, 'V': 0.47750420743737804}, {'N': 0.47895371918873647, 'V': 0.5210462808112636}, {'N': 0.47895371918873647, 'V': 0.5210462808112636}, {'N': 0.5074481492821894, 'V': 0.49255185071781066}]
naive_bayes_classify=['N', 'N']
naive_bayes_acc=0.6065857885615251
answer_open_question_8='The best accuracy was achieved using a sequence of words. Indicating that\nthis model is most useful when passed a sequence of words.\n\nMy NB accuracy is worse than all LR scores in Table 1. I believe this\ndifference can mainly be attributed to the NB independence assumption\nas this infers probability distributions about features that are likely\nnot true. Thus a model that does not assume any distribution would be\nmore useful.'
lr_predictions='VVVVVVVVVNVVVVVVVVVVVVVVVVVVVNVVVVVVVVNVNVVVNVNNNNVVNVVVNNVNNNVNNVVVNNVVVNNNVVNVNVNVNNNVVVNVNNVVVVNVNNVNVVVVNVNNVNNNNVVVNVVNVVNVVNVNNVNVNNNVVNNNNVNNNNVNNVNVVNNNNVNNNNNNNNNNVVNNVVVVVVVNVNVNNVNVVVVNVVVVVVNNNNNVVNVNNNNNNVNVVVNNNVNNNNVNNNVNNVNNVNNVNNNNVVNNNNVNVNVNNVVVNNNNNVVNNNVNVVVVVVNVVNVNNVNNVVVNNVVNVVNNNNNVNVNNVVVNNNVVVVNVVVVVNVNNNNVVVNNNNNVNVNVNNVVNVNNNVNVNVNVVNVVVNNNNNNNVVVVVVNNNNNNVVNVVNNNNNNVNNVVVNNVVVVVVVVNNNVNVNVVVNNVVVVVVVVVNVVVVNVNVNNVVNVVVVVNNNNNVVVVNNNVVVNNNVVNVNNVNNNVNNNVNVNVVVVVVNVVNVNNVNNVNNVVVNVNNVVVVVVVVVVVVVVVNVNVVVNVNNVVNVVNNNNNNVVNNNNVNVNVVNNNNNNVVNNNNVVVVVNNVNVNNNVVNVVNVNVVNVNVVVVVVVNVNNNVVNNVVVNNNNVNVVNVVNVNNVVNVVVVNVVVNVNVVNVNNVNVVNVVNVNNNNNVVNNVNNNVVNNVVVVVVNVVVVVVVVVVVVVVVVNVNVVNNVVVVVVNVNNNNNVVNNNNVNNNNVVVVNNVVVNVNNVNVVVVVNNNNNNNVNNVNVNNVVVVNNNNNNVVVNVVVVVVVVNVNVVVNVNVNVVNVNNNVVNVNNNVNVNVNVVNVVNVVNNNNVNNVVNVVVNVVVVNVNVNNVNNNNVNNNNNVVVNNNNVVNNVNNVVNVVNVNNNNVNNNNVNVVVNVNNNVVNVVNNNVNNVNNNNNNVNNNVNVNVNVVVNVVNNVNNNVVNVVVVNVNVNNNVVVNNNNNNVVNVNNNNVVVVVVVNVVVVVNNVVVVVNNVVVNNNVVVVNVNNVNVNNNNNNVVNNNNVVVVVNVNVNVVVNNVNNVNVVNNNVNVNVNNVNVNVNVNVVVNVVNVNNVVVVNNNNVNNNNVNVNNVNVNNNNVVVNVVNNNVNNVVVVVNVNNNVNNNNNVVVVVVVVVNVVVVVNNVNVVVNNNVVNVVNVVVNVVVVVNNNNNNNNNNNNNNVNNVNNNVNNNNNVNVVNVVNVNNNVVVNVVVNNVNNNVVVNVNNVVNNNNNNNNNNNNVVVNVVNVNNNVVVNVNVVVNVVVNVVVNNNNVVNNNNNVVVNVNNNNNNNVVVNNVNVNVNVNNNVVNVNNVVVNVVVVVNVNNVVNNVNVNVNVVVNVVVVNVVVNNVNNNNVNVVNVNVVNNVVNVNVNNVVVNVNNNVVNNNVNVVNNNNVVVNNVVVVVNNNNNNNVVVNVNVVVVNNVNNNNVVNVVVNNNNVVNNVNNNNNNNNVNNNVNNNNNNNNVNNVNVVVNVVNNVNNVVNNNNNNVNNVVNNVVVVNNVNNNVVVNVNNVVNVNVNNNVNNVNNVNNNNNVNNVNNVNNNNVVNVNNVNNVNVNVNVNNVVVVVVNNVNNVNNVVVVNNNVVVVNVNVNVVNNNVNNNNNNVNVNVNVVVNNVNNNVNVVVVNVNNNVNVNVNVVVNVVNVVVVVNNVVVNNNNVVNNVVNNNVNVNNNVNNVNNVNNNVNNNVNVVNVVNVVVNNNVNNNVNNNNNNNNNNNNNVVVNVVVNVVVVVVNVVNVNVVVNNNVNNNNVVNVNVVVNVNVNVVVNVNNNNVVNVNNVNNVNNNNNNNVNVNVNNVNNNVVVNVVVNNNNNNNVNVNNNVNNVVNNNNNVNNNNNVNNVNVNNNNVVNNVVVVNVNVVVVNNVNVNVVVVVNNNVNNNNVVNVNNNNVNVVNNNNNNVNVNVVVNNVVNNNNVNNVNVVNNNNNVNNNVNVNNNNVNNVVNNVNNVNVNNVNNNVVVVNVNVNVNNVNVNVVVVVNVNVNNNVNVNVNNVNVNVNNVVNNNVVNNVVNVNVVNVVNNNNVNNNNNNVNVVVNNNVVVNVNVVVVVNVVVVNNNVVNVNNNNVVNVVNNVNVVVNVVVNNNVVNNVVVNNVVNNVVVVNNNNNVVVVNNNNNNVNVVVNVVNVNVVNNNVNNVNVNVVNNVVVNNVVVVVNNVNVVNNVVNVVVNVNVNVNVNNVVVVVVVVNNVVVVNVVVNVNNNNNNVVVNNNNVNNVVVNVVNVNNVVNNVNVNNVNVVVNNNVNVNVNVNNVVVVNNNNNVVVVNVVNVVVVNNNVVNVVNNVVVNNNVNNNNVNNNNVVNVNNVVVNNNNVNVVNVVNVNVNNVVVVNNVNNNVVVVVNVVNVVNVNNNNNVVNNVNNNVNNNNNVNVVVNVVVNVNVNNNVNVVVNNNVVVNNVVNVVNNVNVNNNNNVVVNNNVNVNNVNNVVNVVNVNNVVVVVVNNNVNNNVNNVVVVNVNVNVNNVVVNNNVNNNNNNNVVNNNNNNNNNVVVNVVNNNVNNVVNVNVVVVNVVVVNNVNVVVNNVVVVNNNVVVVNNVVVNVNVVVVNVVVVNNNVNVVNVNVVVNNVNNVVNVVVNNNNVNVVVVVVVVNNNVNNVNNNNVNVVNNVVVNNNNVVVVVNNVNNNNNVVVNVVNNVNVNNVVVVVVNVNVVVVNVNVNNNNNNNVVNVNVNVVNNVVNVNNVNVNNNNNNVVNNNVVVVVNNNNVVVVNNVVVVVVVVNNVNNVVNNVNVVNNNNVVNNVNNVVVVVNVVVNNVVVVNVNNVNNNVVVNVVVVVVVVNNVNVNVVNNVNVVVVVVNNVVVNVVVNVVVVNVVNNNVNNNVVVVNVVNVVNNVVVNVVVVNNVVNNVNNVNVNVNNVNVNNNNNVNNNVVVVNNNNNNVNNVNVNNVNVNNNNNNNVNNNNNVVVVVVVNNNVVVNNNVVNVVVNNNNNNVVVVVVNVVVVVNNVVVVNVVVNNVVNVVVVNNNNNNVVNVNNVVVNNNNVVNNVNNNVVVVVVNVVVNVNVNVNNVVVNNNVNVNNNVNNNNNNNVNNVVVNNVNNVNNNVNVNVNNNNNVVVVNVNVNVVVVVVVVVVVVVVVVVNNNVNNVVNVVNVVNVVVNNVNVVNNNNVVVVVVNNNNNVNNNNNVNNNVVNNNVNVVVNNVNNNVNNVVNNNNNVVVVVVVNVNVVVVNNVNNNNVNNNNNVNVVVVNVNNNVVVNNVVNNNVNNVVVNVNVVNNNVVNNNVVVVNVVNNVVNNVVNVVNVNVNNNNNNNVNNVNVVVVVNNVNVNNNNNVNVNVVVVVNVNVNNVNNVNNNVVVNNVVNVVVVVVNVNVVVVVVNVNVVVVNNVVVNVVVNVNNVVNNNVNVVNNNVVVNVNNNNVNVNVVVVVVVVVVNVVNNNNNNVVVNVVNNNVNVNNVNVNNVVNVVNNVVVVNVVVNNNVVVVVVNNNVNNVVVVNVNNNVNVVNVVNNNNVNVVNVNNVVVNNNVVNVVNNNNVVVVVVVNVVNNVVNNNNVVVVVVNNVVVVNNVNNVNVNNVNNVVNVVNNNNNVNVVNVNVVVNVNVNVVNVVVNVVVNNVNVNNNNNNVNVVNVVNVVVVVVNNNNNVVNNNNVVVVVVVNNNNVNNNNVVVNNNVVNNVVNVVNVVVNNVNNVVVVVNVVNNVNNVVVVVVVNNVVVNNNNNNVVNNNNVVVNNNNVVNNVNNVNVNVVVVNNNNVNVVNNNVNVNNVVNVVVNNNVVNNVNVVNNNVNVNVNVNVNVVVVVNNNNVVNVNNNVNNNVNNNNNNNVNVVNVNNNVNNNVNNNNVVVVNVVNVVNVNNNVNNNNNNNNNNVNNNVNVNVNVNVNVNNVNVNVNVVVNVVVVNNVNVNVNNNVNNNNNNVNVVVVNNVNNNNNNNNVNNVNNVVNNVNVVVVVNVVNNNVVNVVVVNVVNNNVNVNNVNVVVNVNVVVVVVVNNNNNNNNVNVNNNVNNNNNVNNVNVNNNVVVVNVNVNVNVNVNVVVNNNNNNVVVVNNNNNNNNNNNVVVVVVNNVVVNVVNNVVVVNNNNVNVNVNNVVNVNNVVVNVVNVVNNVNVNNVN'
answer_open_question_9='...'
